<p><i>This is the third post in the Attention Economy series. Here are the <a href="/#!post/attention-economy">first</a> and <a href="/#!post/apps-are-bad">second</a> posts.</i></p>
<hr>
<p>
  In 2006, the Harvard Business Review magazine published an article titled <a href="https://hbr.org/2006/01/evidence-based-management" target="_blank">"Evidence-Based Management."</a> It opens like this:
</p>
<p><i>
    A bold new way of thinking has taken the medical establishment by storm in the past decade: the idea that decisions in medical care should be based on the latest and best knowledge of what actually works. Dr. David Sackett, the individual most associated with evidence-based medicine, defines it as “the conscientious, explicit and judicious use of current best evidence in making decisions about the care of individual patients.” Sackett, his colleagues at McMaster University in Ontario, Canada, and the growing number of physicians joining the movement are committed to identifying, disseminating, and, most importantly, applying research that is soundly conducted and clinically relevant.
</i></p>
<p>
  I don't think this will be a controversial stance among my readers. Science, i.e. the systematic search for knowledge and truth via testable hypotheses and reproducible experimentation, is pretty cool. Doctors should absolutely rely on science when making decisions about healthcare.
</p><p>
  In the two paragraphs after this, the authors argue that like doctors, managers should rely on science and evidence to make their decisions. They discuss various findings by researchers that go against standard practice in both medicine and organiztional management, but then they then do a very tricky, perhaps accidental sleight of hand; they conflate science done by scientific practitioners with "science" using data internally within a corporation. It starts with this anecdote:
</p>
<i><p>
    When it comes to setting the tone for evidence-based management, we have met few chief executives on a par with Kent Thiry, the CEO of DaVita, a $2 billion operator of kidney dialysis centers headquartered in El Segundo, California. Thiry joined DaVita in October 1999, when the company was in default on its bank loans, could barely meet payroll, and was close to bankruptcy. A big part of his turnaround effort has been to educate the many facility administrators, a large proportion of them nurses, in the use of data to guide their decisions.
  </p>
  <p>
    To ensure that the company has the information necessary to assess its operations, the senior management team and DaVita’s chief technical officer, Harlan Cleaver, have been relentless in building and installing systems that help leaders at all levels understand how well they are doing. One of Thiry’s mottoes is “No brag, just facts.” When he stands up at DaVita Academy, a meeting of about 400 frontline employees from throughout the organization, and states that the company has the best quality of treatment in the industry, that assertion is demonstrated with specific, quantitative comparisons.
  </p>
  <p>
    A large part of the company’s culture is a commitment to the quality of patient care. To reinforce this value, managers always begin reports and meetings with data on the effectiveness of the dialysis treatments and on patient health and well-being. And each facility administrator gets an eight-page report every month that shows a number of measures of the quality of care, which are summarized in a DaVita Quality Index. This emphasis on evidence also extends to management issues—administrators get information on operations, including treatments per day, teammate (employee) retention, the retention of higher-paying private pay patients, and a number of resource utilization measures such as labor hours per treatment and controllable expenses.
  </p>
</i>
<p>
  And now I have objections. Science is hard. So hard, in fact, that trained and dedicated scientists struggle with it. This is perhaps best exemplified by the <a href="https://en.wikipedia.org/wiki/Replication_crisis">replication crisis</a>, which calls into question the credibility of much of our scentific knowledge. <!-- The scientific community tries to mitigate the innate difficulty of understanding the universe by developing community-wide standards and best practices, like <a href="https://en.wikipedia.org/wiki/Peer_review">peer review</a>. They usually organize themselves into universities that each employ hundreds if not thousands of professors overseeing and collaborating with various kinds of students and/or researchers to facilitate the complex, intergenerational process of learning necessary to do good science. -->
</p>
<p>
  Comparing corporations to the scientific community makes it obvious that these organizations do not exist to accomplish the same function. First, the obvious: corporations seek profit, while scientists seek truth. Profit, a corporation's true purpose, and its mission or stated societal role, are often in tension. The tension here is obvious in the anecdote provided above when the company's CTO "states that the company has the best quality of treatment in the industry, that assertion is demonstrated with specific, quantitative comparisons." Yet, in the proceeding paragraph, the examples given for these quantiative comparisons are "treatments per day, teammate (employee) retention, the retention of higher-paying private pay patients, and a number of resource utilization measures such as labor hours per treatment and controllable expenses."
</p>
<p>
  The claim that the company has the "highest quality treatment" is obviously intermingled with the company's profitability. That is bad science. The 400 nurses that Mr. Thiry "educated," had we their side of the story, would probably tell you that spending less time with patients will generally decrease the quality of care while increasing profit.
</p>
<p>
  I am not saying that corporations should avoid using metrics — I don't even think corporations as we know them should exist. I am saying that with this emphasis on being "data-driven" and "scientific," the business community has created a tradition much like those derided in this HBR article. They mime the aesthetic of science without its substance. Self-declared data-driven businesses are a <a href="https://en.wikipedia.org/wiki/Cargo_cult">cargo cult</a>, performing empty scientific rituals in the millernarian belief that their businesses will be transformed into a <a href="https://en.wikipedia.org/wiki/List_of_unicorn_startup_companies">unicorn</a>.
</p>
<h3>How Data-Driven Business Culture Created The Attention Economy</h3>
<p>
  I propose that the attention economy exists because measuring user engagement is the single easiest thing for tech companies to measure. It was not necessarily most profitable for tech companies to focus on maximizing engagement in order to hoard user data; instead, these companies seek data to satisfy their cultural need to appear rational and scientific. They are "data-driven" in a much more literal sense; they have chosen to focus their efforts on the most easily measurable things.
</p>
<p>
  I chose the 2006 HBR article to start because this desire for data-driven decision making in business predates modern big tech. It is the cultural milieu into which they were born. When the nature of the internet made it so easy to generate data, the businesses' cultural desire for data fundamentally shaped the entire industry.
</p>
<p>
  You can see these cultural values shaping the business in this much more recent article titled "<a href="https://hbr.org/2020/02/10-steps-to-creating-a-data-driven-culture">10 Steps to Creating a Data-Driven Culture</a>." Several of the 10 steps recomend changing the way products are made. Here is number 6, titled "make proofs of concept simple and robust, not fancy and brittle:"
</p>
<i>
  <p>
    In analytics, promising ideas greatly outnumber practical ones. Often, it’s not until firms try to put proofs of concept into production that the difference becomes clear. One large insurer held an internal hackathon and crowned its winner — an elegant improvement of an online process — only to scrap the idea because it seemed to require costly changes to underlying systems. Snuffing out good ideas in this way can be demoralizing for organizations.
  </p>
  <p>
    A better approach is to engineer proofs of concept where a core part of the concept is its viability in production. One good way is to start to build something that is industrial grade but trivially simple, and later ratchet up the level of sophistication. For example, to implement new risk models on a large, distributed computing system, a data products company started by implementing an extremely basic process that worked end-to-end: a small dataset flowed correctly from source systems and through a simple model and was then transmitted to end users. Once that was in place, and knowing that the whole still cohered, the firm could improve each component independently: greater data volumes, more exotic models, and better runtime performance.
  </p>
</i>
<p>
  This parable of the data products company shows us it is better to make a simple product that gets the data flowing, juxtaposing that with the user experience improvements that are too expensive to implement. Despite the admission that the user experience upgrade was a "good idea" and even "elegant," it is less desirable. The parable does not tell us why it is seen as "too costly" to implement. From context, I suspect its impact is not as easily quantifiable.
</p>
<p>
  Again, I want to reiterate that I do not really care whether this is good business advice or not. Instead, I wish to point out that taken in aggregate, advice like this has created the technological world we know. Companies prioritize simple products with immediatley measurable results vs complex undertakings that they freely admit would improve their product. They are explicitly optimizing their measurability/effort ratio. They seek to decrease the amount of work they put into a project before they can start applying metrics to it.
</p>
<p>
  There are dozens of articles out there just like that one. Tableau, a very successful Data Visualization SaaS company, <a href="https://www.tableau.com/learn/articles/how-to-build-a-data-driven-organization">writes many articles about how to build a "data-driven" organization</a>, or how to <a href="https://hbr.org/2020/02/10-steps-to-creating-a-data-driven-culture">create a data-driven culture</a>. Tableau has successfuly monetized the cargo cult by combining the scientific practice of visualizing data with the middle-manager's need to impress their boss with fancy powerpoint presentations. They bill themselves as "the world’s leading analytics platform," with the tagline "successful business forecasts, decisions, and strategies are driven by data."
</p>
<h3>Then Why Is Tech So Profitable?</h3>
<p>
  It's not. "Successful" tech companies regularly lose billions of dollars. SnapChat, a publicly traded company worth $13.4 billion, <a href="https://investor.snap.com/news/news-details/2022/Snap-Inc.-Announces-Third-Quarter-2022-Financial-Results/default.aspx#:~:text=As%20of%20September%2030%2C%202022,cash%20equivalents%2C%20and%20marketable%20securities.&text=Revenue%20increased%206%25%20to%20%241%2C128,million%20in%20the%20prior%20year.">a net loss of $360 million in Q3 of 2022</a>. This is typical for them since they've gone public. In 2018, they were worth $21.7 billion, but had lost $1.3 billion that year.
</p>
<p>
  TikTok <a href="https://www.forbes.com/sites/russellflannery/2022/10/06/operating-loss-at-tiktok-parent-bytedance-topped-7-billion-last-year-wsj-reports/?sh=7e016aa727c2"> operates at a loss</a>. Youtube was a money pit for years, finally turning a profit in the late 2010s, only to <a href="https://www.cnbc.com/2022/04/26/youtubes-huge-miss-shows-digital-media-ad-market-is-getting-hit-hard.html">quickly start missing targets and losing market share to TikTok</a>. Twitter was <a href="https://www.buzzfeednews.com/article/alexkantrowitz/how-twitter-made-the-tech-worlds-most-unlikely-comeback">constantly struggling to stay afloat, until it was given new life when the United States elected a barely literate president for whom the characater limit is a necessary crutch</a>. Now that Musk owns it, it is again hemorrhaging money.
</p>
<p>
  I am not saying that all tech companies aren't profitable, but I am saying that many of them, despite being "worth" tens of billions or more, operate at a loss. Tech companies are valuable because investors like them, and how could they not? Investors, like tech companies, self-identify as being "rational" and "data-driven," and tech companies produce so much data for them to consume. It's a perfect match.
</p>


<!-- https://hbr.org/2006/01/evidence-based-management -->
<!-- https://www.tableau.com/learn/articles/how-to-build-a-data-driven-organization -->
<!-- https://www.tableau.com/why-tableau/data-culture -->
<!-- https://hbr.org/2020/02/10-steps-to-creating-a-data-driven-culture -->
<!-- https://hbr.org/2022/02/why-becoming-a-data-driven-organization-is-so-hard -->
